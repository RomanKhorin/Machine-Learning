{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec, Word2Vec\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk, nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1. Обучите модель word2vec. Оцените время обучения модели, используя модуль time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тем, как обучить модель, разобьем наши тексты на список предложений, где каждое предложение представляет из себя список слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала считаем данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeledData = pd.read_csv(\"unlabeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "testData = pd.read_csv(\"testData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "labeledData = pd.read_csv(\"labeledTrainData.tsv\", header=0, \\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необработанный текст выглядит как-то так."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Naturally in a film who\\'s main themes are of mortality, nostalgia, and loss of innocence it is perhaps not surprising that it is rated more highly by older viewers than younger ones. However there is a craftsmanship and completeness to the film which anyone can enjoy. The pace is steady and constant, the characters full and engaging, the relationships and interactions natural showing that you do not need floods of tears to show emotion, screams to show fear, shouting to show dispute or violence to show anger. Naturally Joyce\\'s short story lends the film a ready made structure as perfect as a polished diamond, but the small changes Huston makes such as the inclusion of the poem fit in neatly. It is truly a masterpiece of tact, subtlety and overwhelming beauty.\"'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData.review[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из общей коллекции текстов создадим список из предложений, в котором каждое преждложение представляет из себя список слов, используя функции convert_to_sentences и convert_to_wordlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Функция преобразует входной документ в последовательность слов.\"\"\"\n",
    "def convert_to_wordlist(text):\n",
    "    # избавляемся от html тегов\n",
    "    clear_text = BeautifulSoup(text, \"lxml\").get_text()\n",
    "    \n",
    "    # избавляемся от пунктуации и цифр\n",
    "    clear_text = re.sub(\"[^a-zA-Z]\",\" \", clear_text)\n",
    "    \n",
    "    # приводим к нижнему регистру и разбиваем\n",
    "    words = clear_text.lower().split()\n",
    "    \n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Функция разбивает входной документ на список предложений,\n",
    "   где каждое предложение представляет из себя список слов.\"\"\"\n",
    "def convert_to_sentences(text, tokenizer):\n",
    "    # Используем NLTK tokenizer, чтобы разбить параграф на предложения.\n",
    "    raw_sentences = tokenizer.tokenize(text.strip())\n",
    "    \n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # Пустые предложения мы не рассматриваем\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Разбиваем непустое предложение на список слов.\n",
    "            sentences.append(convert_to_wordlist( raw_sentence))\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_list = [labeledData, unlabeledData, testData]\n",
    "\n",
    "sentences = []\n",
    "\n",
    "for df in df_list:\n",
    "    for review in df.review:\n",
    "        sentences += convert_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге у нас получилось больше одного миллиона предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056938"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое предложение в списке спиков представляет из себя совокупность слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with',\n",
       " 'all',\n",
       " 'this',\n",
       " 'stuff',\n",
       " 'going',\n",
       " 'down',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " 'with',\n",
       " 'mj',\n",
       " 'i',\n",
       " 've',\n",
       " 'started',\n",
       " 'listening',\n",
       " 'to',\n",
       " 'his',\n",
       " 'music',\n",
       " 'watching',\n",
       " 'the',\n",
       " 'odd',\n",
       " 'documentary',\n",
       " 'here',\n",
       " 'and',\n",
       " 'there',\n",
       " 'watched',\n",
       " 'the',\n",
       " 'wiz',\n",
       " 'and',\n",
       " 'watched',\n",
       " 'moonwalker',\n",
       " 'again']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим нашу модель word2vec, используя данные, которые мы подготовили. Для обучения будем использовать skip-gram, потому что выборка текстов небольшая. Размер окна положим равным 10, субсэмплирование определим на уровне 1e-3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 30s\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# params = {\n",
    "#     'sentences' : sentences,\n",
    "#     'size' : 300,\n",
    "#     'window' : 10,\n",
    "#     'sample' : 1e-3,\n",
    "#     'workers' : 4,\n",
    "#     'min_count' : 35,\n",
    "#     'sg' : 1\n",
    "# }\n",
    "\n",
    "# обучаем нашу модель word2vec\n",
    "\n",
    "# model = Word2Vec(**params)\n",
    "\n",
    "# model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним обученную модель, чтобы не обучать ее каждый раз заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model_name = \"model_khorinr\"\n",
    "\n",
    "# сохраняем нашу модель, чтобы не обучать ее заново и использовать в будущем\n",
    "# model.save(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем модель, обученную ранее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Word2Vec.load('model_khorinr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2. Приведите 5-10 примеров использования .most_similar для определения близких слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдем топ-5 похожих слов, используя функцию __.most_similar__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sadness', 0.7091981768608093),\n",
       " ('despair', 0.6270290613174438),\n",
       " ('helplessness', 0.6189005374908447),\n",
       " ('pain', 0.5961489677429199),\n",
       " ('heartache', 0.5872154235839844)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('sorrow', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('smart', 0.620033323764801),\n",
       " ('thoughtful', 0.5956170558929443),\n",
       " ('witty', 0.5712857246398926),\n",
       " ('clever', 0.5506004095077515),\n",
       " ('literate', 0.5464425086975098)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('intelligent', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afghanistan', 0.612485945224762),\n",
       " ('iraqi', 0.5733760595321655),\n",
       " ('vietnam', 0.5672841668128967),\n",
       " ('war', 0.5660949945449829),\n",
       " ('yugoslavia', 0.5499035716056824)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('iraq', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('soccer', 0.6276072859764099),\n",
       " ('baseball', 0.6067206263542175),\n",
       " ('basketball', 0.592818558216095),\n",
       " ('rugby', 0.5741385817527771),\n",
       " ('coach', 0.560568630695343)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('football', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('agony', 0.6327665448188782),\n",
       " ('anguish', 0.6102206707000732),\n",
       " ('sorrow', 0.5961489677429199),\n",
       " ('grief', 0.5655539035797119),\n",
       " ('heartache', 0.5548940896987915)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('pain', topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель находит близкие слова достаточно хорошо. В большинстве случаев найденные слова действительно являются синонимами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3. Приведите 5-10 примеров использования most_similar для определения ассоциаций (А к Б, как В к?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для нахождения ассоциаций между словами так же будем использовать функцию most_similar.\n",
    "<p>Попробуем следующие примеры слов:</p>\n",
    "* big bigger bad\n",
    "* man son girl\n",
    "* he his she\n",
    "* russia russian america\n",
    "* boy man girl\n",
    "* go went run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В итоге получаем следующие ассоциации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'big' к 'bigger' как 'bad' к 'worse'\n",
      "\n",
      "'man' к 'son' как 'woman' к 'daughter'\n",
      "\n",
      "'he' к 'his' как 'she' к 'her'\n",
      "\n",
      "'russia' к 'russian' как 'america' к 'american'\n",
      "\n",
      "'boy' к 'man' как 'girl' к 'woman'\n",
      "\n",
      "'go' к 'went' как 'run' к 'ran'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_examples = ['big bigger bad',\n",
    "                  'man son woman',\n",
    "                  'he his she',\n",
    "                  'russia russian america',\n",
    "                  'boy man girl',\n",
    "                  'go went run']\n",
    "\n",
    "for example in words_examples:\n",
    "    a, b, c = example.split()\n",
    "    association = model.most_similar([c, b], [a])[0][0]\n",
    "    print(\"'%s' к '%s' как '%s' к '%s'\\n\" % (a, b, c, association))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что все ассоциации определены верно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #4. Приведите 5-10 примеров использования .doesnt_match для определения лишнего слова."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попытаемся найти лишние слова, используя функцию .doesnt_match для следующих примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clutch'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"shotgun clutch pistol bullet projectile\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'judge'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"poet judge playwright dramatist\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'silly'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"smart intelligent silly clever\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attack'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"blue yellow attack green red\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'odd'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"refund raise odd procure repayment\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из примеров, модель определяет лишние слова достаточно хорошо. Из примеров все лишние слова найдены корректно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #5.1. Попробуйте найти такие пары и тройки слов, для которых НЕ выполняются свойства коммутативности и транзитивности относительно операции определения близких слов (входить в топ-3 по .most_similar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коммутативность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Пары слов __experiences__ и __life__ не являются коммутативными. Так, experiences входит в top-3 по близости к слову life, но life в топ-3 по близости к слову experiences не входит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lives', 0.5257035493850708),\n",
       " ('sorrows', 0.4022024869918823),\n",
       " ('experiences', 0.38946056365966797)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('life', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('experience', 0.5324373841285706),\n",
       " ('joys', 0.4490772485733032),\n",
       " ('discoveries', 0.440945029258728)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('experiences', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Пары слов __bobbing__ и __water__ так же не являются коммутативными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('swimming', 0.5230377912521362),\n",
       " ('fish', 0.49989980459213257),\n",
       " ('bobbing', 0.4936462342739105)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('water', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sails', 0.638393759727478),\n",
       " ('flapping', 0.6207567453384399),\n",
       " ('swirling', 0.6143648028373718)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('bobbing', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Транзитивность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Тройка слов __god, jesus, christ__ не является транзитивной.\n",
    "<p>God входит в топ-3 по most_similar слова jesus, jesus входит в топ-3 по most_similar слова christ, но god __не__ входит в топ-3 по most_similar слова christ.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('christ', 0.7511848211288452),\n",
       " ('god', 0.49731725454330444),\n",
       " ('judas', 0.491919606924057)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('jesus', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jesus', 0.7511848211288452),\n",
       " ('teachings', 0.4705061614513397),\n",
       " ('judas', 0.46374014019966125)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('christ', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Тройка слов __russia, ussr, germany__ так же не является транзитивной.\n",
    "<p>USSR входит в топ-3 по most_similar слова russia, russia входит в топ-3 по most_similar слова germany, но USSR __не__ входит в топ-3 по most_similar слова germany.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.6032990217208862),\n",
       " ('ussr', 0.5540001392364502),\n",
       " ('bulgaria', 0.5516657829284668)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('russia', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('europe', 0.6586641073226929),\n",
       " ('poland', 0.6117411851882935),\n",
       " ('russia', 0.6032990217208862)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('germany', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #5.2. Попробуйте найти такие пары и тройки слов, для которых выполняются свойства коммутативности и транзитивности относительно операции определения близких слов (входить в топ-3 по .most_similar)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Коммутативность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Пары слов __iraq__ и __afghanistan__ являются коммутативными. Они оба входят в топ-3 по близости относительно друг друга."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('afghanistan', 0.612485945224762),\n",
       " ('iraqi', 0.5733760595321655),\n",
       " ('vietnam', 0.5672841668128967)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('iraq', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('taliban', 0.682716965675354),\n",
       " ('iraq', 0.612485945224762),\n",
       " ('pakistan', 0.6068713665008545)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('afghanistan', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Пары слов __jesus__ и __christ__ так же являются коммутативными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('christ', 0.7511848211288452),\n",
       " ('god', 0.49731725454330444),\n",
       " ('judas', 0.491919606924057)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('jesus', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jesus', 0.7511848211288452),\n",
       " ('teachings', 0.4705061614513397),\n",
       " ('judas', 0.46374014019966125)]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('christ', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Транзитивность"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Тройка слов __launcher, handgun, grenade__ является транзитивной.\n",
    "<p>Launcher входит в топ-3 по most_similar слова handgun, handgun входит в топ-3 по most_similar слова grenade, launcher так же входит в топ-3 по most_similar слова grenade.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dart', 0.6749066114425659),\n",
       " ('launcher', 0.6716697812080383),\n",
       " ('pistol', 0.6707010269165039)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('handgun', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('launcher', 0.723590612411499),\n",
       " ('grenades', 0.6451822519302368),\n",
       " ('handgun', 0.6407240033149719)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('grenade', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Тройка слов __portugal__, __spain__, __france__ так же является транзитивной.\n",
    "<p>Portugal входит в топ-3 по most_similar слова spain, spain входит в топ-3 по most_similar слова france, portugal так же входит в топ-3 по most_similar слова france.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('france', 0.6373680830001831),\n",
       " ('portugal', 0.6348042488098145),\n",
       " ('italy', 0.5802099704742432)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('spain', topn=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('belgium', 0.6461061239242554),\n",
       " ('spain', 0.6373680830001831),\n",
       " ('portugal', 0.6353395581245422)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('france', topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После выполнения всех пунктов данного дз можно сказать, что Word2Vec является удобным и мощным инструментов для выявления семантической близости слов, расчета векторных представлений слов, а также для нахождения ассоциаций и выявления лишних слов в предложениях. Умело обученная модель успешно способна справиться со всеми задачами такого типа."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
